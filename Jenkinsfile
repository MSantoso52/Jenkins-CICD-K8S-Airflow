pipeline {
    agent any
    
    environment {
        // GitHub repo details
        GITHUB_REPO = 'https://github.com/MSantoso52/Jenkins-CICD-K8S-Airflow.git'
        AIRFLOW_NAMESPACE = 'elt-pipeline'
        AIRFLOW_VERSION = '3.0.2'
    }
    
    stages {
        stage('Load - Checkout Code') {
            steps {
                echo 'üöÄ Loading code from GitHub...' [cite: 2]
                git branch: 'main', 
                    url: env.GITHUB_REPO,
                    credentialsId: 'github-credentials' 
                
                // Verify files exist
                script {
                    sh 'ls -la'
                    sh 'test -f sales_elt_dag.py || (echo "DAG file missing!" && exit 1)' [cite: 3, 4]
                    sh 'test -f test_dag.py || (echo "Test file missing!" && exit 1)' [cite: 4, 5]
                    sh 'test -f sales_record.json || (echo "Data file missing!" && exit 1)' [cite: 5, 6]
                }
            }
        }
        
        stage('Test - Validate DAG & Data Quality') {
            steps {
                echo 'üß™ Running comprehensive DAG tests...' [cite: 7]
                script {
                    // Install Python dependencies
                    sh '''
                        python3 -m pip install --user --upgrade pip --break-system-packages
                        python3 -m pip install --user numpy==1.24.3 --break-system-packages [cite: 8]
                        python3 -m pip install --user pytest==7.4.0 apache-airflow==${AIRFLOW_VERSION} pandas==2.0.3 sqlalchemy psycopg2-binary pytest-mock --break-system-packages [cite: 8]
                    '''
                    // Run pytest with verbose output and generate JUnit XML report
                    sh '''
                        python3 -m pytest test_dag.py -v --tb=short -x --junitxml=target/pytest/test-results.xml
                    '''
                    // The following command is used to generate the HTML report.
                    // You would need a separate tool like `pytest-html` for this,
                    // which is not included in the original script.
                    // For now, let's focus on the JUnit fix.
                    sh 'mkdir -p target/pytest && echo "<html><body><h1>Test Report</h1><p>Tests ran successfully.</p></body></html>" > target/pytest/index.html'

                    // Additional static analysis
                    sh '''
                        echo "Running pylint on DAG..." [cite: 11]
                        python3 -m pip install --user pylint --break-system-packages [cite: 11]
                        pylint sales_elt_dag.py || true [cite: 11, 12]
                        
                        echo "Running flake8 for style checks..."
                        python3 -m pip install --user flake8 --break-system-packages [cite: 13]
                        flake8 sales_elt_dag.py || true [cite: 13, 14]
                    '''
                    
                    // Test JSON file validity
                    sh '''
                        echo "Validating JSON file..." [cite: 15]
                        python3 -c "
import json
with open('sales_record.json', 'r') as f:
    data = json.load(f)
print(f'‚úì JSON valid with {len(data)} records')
"
                    '''
                }
            }
            post {
                always {
                    // Archive test results
                    junit 'target/pytest/test-results.xml'
                    publishHTML([
                        allowMissing: false, [cite: 17]
                        alwaysLinkToLastBuild: true, [cite: 17]
                        keepAll: true, [cite: 17]
                        reportDir: 'target/pytest', [cite: 17]
                        reportFiles: 'index.html', [cite: 18]
                        reportName: 'DAG Test Report' [cite: 18]
                    ])
                }
                failure {
                    echo '‚ùå DAG tests failed! Pipeline stopped.' [cite: 19, 20]
                    emailext (
                        subject: "DAG Test FAILED: ${env.JOB_NAME} - ${env.BUILD_NUMBER}",
                        body: "The DAG tests failed. Please check the console output.",
                        to: 'your-email@example.com' [cite: 20, 21]
                    )
                }
            }
        }
        
        stage('Load - Deploy to Airflow on Kubernetes') {
            when {
                expression { currentBuild.result == null || currentBuild.result == 'SUCCESS' } [cite: 22, 23]
            }
            steps {
                echo 'üì§ Deploying DAG to Airflow on Kubernetes...' [cite: 24]
                script {
                    sh '''
                        echo "Copying DAG to Kubernetes cluster..."
                        kubectl cp sales_elt_dag.py ${AIRFLOW_NAMESPACE}/airflow-webserver-xxx:/opt/airflow/dags/ || echo "Webserver copy failed, trying scheduler" [cite: 25, 26]
                        kubectl cp sales_elt_dag.py ${AIRFLOW_NAMESPACE}/airflow-scheduler-xxx:/opt/airflow/dags/ || echo "Scheduler copy failed, trying alternative method" [cite: 26, 27]
                        
                        kubectl create configmap sales-dag-config --from-file=sales_elt_dag.py=sales_elt_dag.py -n ${AIRFLOW_NAMESPACE} --dry-run=client -o yaml | kubectl apply -f - [cite: 28]
                        
                        echo "Resyncing Airflow DAGs..."
                        kubectl exec -n ${AIRFLOW_NAMESPACE} deployment/airflow-scheduler -- airflow dags resync [cite: 29]
                        kubectl exec -n ${AIRFLOW_NAMESPACE} deployment/airflow-webserver -- airflow dags resync [cite: 29]
                        
                        echo "Waiting for DAG to appear..."
                        sleep 10 [cite: 30]
                        
                        echo "Verifying DAG deployment..." [cite: 30]
                        kubectl exec -n ${AIRFLOW_NAMESPACE} deployment/airflow-webserver -- airflow dags list | grep sales_elt_dag || echo "DAG may take a moment to appear" [cite: 31, 32]
                    '''
                    
                    // Test database connectivity (optional)
                    sh '''
                        echo "Testing PostgreSQL connectivity from Airflow..." [cite: 33]
                        kubectl exec -n ${AIRFLOW_NAMESPACE} deployment/airflow-scheduler -- python3 -c "
from sqlalchemy import create_engine
try:
    engine = create_engine('postgresql://airflow:airflow@postgres:5432/airflow')
    with engine.connect() as conn:
        result = conn.execute('SELECT 1')
        print('‚úì PostgreSQL connection successful')
except Exception as e:
    print(f'‚úó PostgreSQL connection failed: {e}') [cite: 34]
"
                    '''
                }
            }
            post {
                success {
                    echo '‚úÖ DAG successfully deployed to Airflow!' [cite: 35]
                    sh '''
                        echo "Triggering test run of the DAG..."
                        kubectl exec -n ${AIRFLOW_NAMESPACE} deployment/airflow-scheduler -- airflow dags trigger sales_elt_dag --conf '{"dry_run": true}' || echo "Test trigger may take a moment" [cite: 36]
                    '''
                    updateGitHubStatus status: 'SUCCESS', message: 'DAG deployed successfully to Airflow' [cite: 37]
                    emailext (
                        subject: "DAG Deployed SUCCESS: ${env.JOB_NAME} - ${env.BUILD_NUMBER}",
                        body: """
                        The sales_elt_dag has been successfully deployed to Airflow in namespace ${AIRFLOW_NAMESPACE}. [cite: 38]
                        
                        View in Airflow: http://your-airflow-url/dags/sales_elt_dag [cite: 39]
                        
                        Build: ${env.BUILD_URL} [cite: 39]
                        """,
                        to: 'your-email@example.com' [cite: 39]
                    )
                }
                failure {
                    echo '‚ùå DAG deployment failed!' [cite: 41]
                    updateGitHubStatus status: 'FAILURE', message: 'DAG deployment to Airflow failed' [cite: 41]
                    emailext (
                        subject: "DAG Deploy FAILED: ${env.JOB_NAME} - ${env.BUILD_NUMBER}",
                        body: "The DAG deployment to Airflow failed. Please check the console output.",
                        to: 'your-email@example.com' [cite: 42]
                    )
                }
            }
        }
    }
    
    post {
        always {
            echo 'üßπ Cleaning up workspace...' [cite: 43]
            cleanWs()
        }
        success {
            echo 'üéâ Pipeline completed successfully!' [cite: 44]
        }
        failure {
            echo 'üí• Pipeline failed!' [cite: 45]
            // slackSend(
            //     color: 'danger',
            //     message: "Pipeline ${env.JOB_NAME} #${env.BUILD_NUMBER} failed: ${env.BUILD_URL}"
            // )
        }
    }
}
